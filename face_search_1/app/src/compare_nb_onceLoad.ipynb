{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model filename: 20170512-110547.pb\n",
      "main\n",
      "detect and align data\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Performs face alignment and calculates L2 distance between the embeddings of images.\"\"\"\n",
    "\n",
    "# MIT License\n",
    "# \n",
    "# Copyright (c) 2016 David Sandberg\n",
    "# \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "# \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "# \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from tensorflow.python.platform import gfile\n",
    "from scipy import misc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import facenet\n",
    "import align.detect_face\n",
    "import time as tm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from pandas  import Series\n",
    "import pylab\n",
    "\n",
    "class Faster_style(object):\n",
    "    \n",
    "    def __init__(self): \n",
    "            self.sess =tf.Session()\n",
    "            #Faster_style.load_model('20170511-185253.pb')\n",
    "            self.load_model('20170512-110547.pb')\n",
    "            self.images_placeholder =  tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "            self.embeddings =  tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "            self.phase_train_placeholder =  tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "           \n",
    "     \n",
    "    def load_model(self,model):\n",
    "        # Check if the model is a model directory (containing a metagraph and a checkpoint file)\n",
    "        #  or if it is a protobuf file with a frozen graph\n",
    "        model_exp = os.path.expanduser(model)\n",
    "        if (os.path.isfile(model_exp)):\n",
    "            print('Model filename: %s' % model_exp)\n",
    "            with gfile.FastGFile(model_exp,'rb') as f:\n",
    "                graph_def = tf.GraphDef()\n",
    "                graph_def.ParseFromString(f.read())\n",
    "                tf.import_graph_def(graph_def, name='')\n",
    "               \n",
    "        else:\n",
    "            print('Model directory: %s' % model_exp)\n",
    "            meta_file, ckpt_file = get_model_filenames(model_exp)\n",
    "            \n",
    "            print('Metagraph file: %s' % meta_file)\n",
    "            print('Checkpoint file: %s' % ckpt_file)\n",
    "          \n",
    "            saver = tf.train.import_meta_graph(os.path.join(model_exp, meta_file))\n",
    "            saver.restore(self.sess, os.path.join(model_exp, ckpt_file))\n",
    "          \n",
    "        \n",
    "        \n",
    "    def main(self,args,image_files):\n",
    "        t1 = tm.time()\n",
    "        print('main')\n",
    "        \n",
    "        images,img_files = self.load_and_align_data(image_files, args.image_size, args.margin, args.gpu_memory_fraction) \n",
    "        \n",
    "        feed_dict = {self.images_placeholder: images,  self.phase_train_placeholder:False }\n",
    "        emb =self.sess.run(self.embeddings, feed_dict=feed_dict)    \n",
    "        print(emb.shape)\n",
    "       # nrof_images = len(args.image_files)\n",
    "        t2 = tm.time()\n",
    "        print (\"==========total take {0}\".format(t2 - t1))\n",
    "        print('Images:')\n",
    "        return emb,img_files\n",
    "       # for i in range(nrof_images):\n",
    "       #     print('%1d: %s' % (i, args.image_files[i]))\n",
    "        #     # Print distance matrix\n",
    "        #    print('Distance matrix')\n",
    "        #    print('    ', end='')\n",
    "        print('')\n",
    "        #for i in range(nrof_images):\n",
    "         #    print('    %1d     ' % i, end='')\n",
    "       # print('')\n",
    "       # for i in range(nrof_images):\n",
    "        #    print('%1d  ' % i, end='')\n",
    "        #    for j in range(nrof_images):\n",
    "          #      dist = np.sqrt(np.sum(np.square(np.subtract(emb[i,:], emb[j,:]))))\n",
    "         #       print('  %1.4f  ' % dist, end='')\n",
    "          #  print('')\n",
    "                      \n",
    "    def load_and_align_data(self,image_paths, image_size, margin, gpu_memory_fraction):   \n",
    "        minsize = 20 # minimum size of face  \n",
    "        threshold = [ 0.6, 0.7, 0.7 ]  # three steps's threshold\n",
    "        factor = 0.709 # scale factor\n",
    "        print('detect and align data')\n",
    "        with tf.Graph().as_default():\n",
    "            gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_memory_fraction)\n",
    "            sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "            with sess.as_default():\n",
    "                pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\n",
    "      \n",
    "        nrof_samples = len(image_paths)\n",
    "        img_files=[]\n",
    "        img_list = []\n",
    "        for i in range(nrof_samples):\n",
    "            img = misc.imread(os.path.expanduser(image_paths[i]), mode='RGB')\n",
    "            img_size = np.asarray(img.shape)[0:2]\n",
    "            bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n",
    "            if(bounding_boxes.shape[0]>0):\n",
    "                det = np.squeeze(bounding_boxes[0,0:4])\n",
    "                bb = np.zeros(4, dtype=np.int32)\n",
    "                bb[0] = np.maximum(det[0]-margin/2, 0)\n",
    "                bb[1] = np.maximum(det[1]-margin/2, 0)\n",
    "                bb[2] = np.minimum(det[2]+margin/2, img_size[1])\n",
    "                bb[3] = np.minimum(det[3]+margin/2, img_size[0])\n",
    "                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n",
    "                aligned = misc.imresize(cropped, (image_size, image_size), interp='bilinear')\n",
    "                prewhitened = facenet.prewhiten(aligned)\n",
    "                img_list.append(prewhitened)\n",
    "                img_files.append(image_paths[i])        \n",
    "        images = np.stack(img_list)\n",
    "        return images,img_files\n",
    "\n",
    "    def parse_arguments(self,argv):\n",
    "        parser = argparse.ArgumentParser()\n",
    "   \n",
    "        parser.add_argument('model', type=str, \n",
    "            help='Could be either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file')\n",
    "        parser.add_argument('image_files', type=str, nargs='+', help='Images to compare')\n",
    "        parser.add_argument('--image_size', type=int,\n",
    "            help='Image size (height, width) in pixels.', default=160)\n",
    "        parser.add_argument('--margin', type=int,\n",
    "            help='Margin for the crop around the bounding box (height, width) in pixels.', default=44)\n",
    "        parser.add_argument('--gpu_memory_fraction', type=float,\n",
    "            help='Upper bound on the amount of GPU memory that will b e used by wthe process.', default=1.0)\n",
    "        return parser.parse_args(argv)\n",
    "\n",
    "#f __name__ == '__main__':\n",
    " #   sys.argv=['compare.py','20170511-185253.pb','image1.jpg','image2.jpg','image3.jpg','image4.jpg','image5.jpg']\n",
    " #   main(parse_arguments(sys.argv[1:]))\n",
    "    def generate_csv(self): \n",
    "        style=Faster_style()\n",
    "        sys.argv=['compare.py','20170511-185253.pb','image.jpg']\n",
    "        argv=style.parse_arguments(sys.argv[1:])\n",
    "        image_files=[]\n",
    "        files = os.listdir('files')\n",
    "        for i in range(len(files)):\n",
    "            image_name = files[i]\n",
    "        \n",
    "            facedir = os.path.join('files', image_name)\n",
    "           \n",
    "            image_files.append(facedir)\n",
    "        count=len(image_files)/100\n",
    "        print(count)\n",
    "        for i in range(int(count)):\n",
    "            imgs=image_files[i*100:i*100+100]\n",
    "            emb,emb_img_files=style.main(argv,imgs)\n",
    "            print(emb.shape)\n",
    "\n",
    "            emb_df=pd.DataFrame(emb)\n",
    "            emb_img_files=np.reshape(emb_img_files,(-1,1))\n",
    "            print(emb_img_files.shape)\n",
    "            path_df=pd.DataFrame(emb_img_files)\n",
    "\n",
    "            res=pd.concat([emb_df,path_df],axis=1, ignore_index=True)\n",
    "            data_info=pd.read_csv('data1.csv',header=None)\n",
    "            data_info=data_info.append(res)\n",
    "            data_info.to_csv('data1.csv',index=False,header=None)\n",
    "           \n",
    "        \n",
    "\n",
    "    \n",
    "    def search(self,image_path):  \n",
    "       \n",
    "        sys.argv=['compare.py','20170511-185253.pb','image.jpg']\n",
    "        argv=style.parse_arguments(sys.argv[1:])\n",
    "        image_files=[]\n",
    "        image_files.append(image_path)\n",
    "        emb,_=self.main(argv,image_files)\n",
    "        data_info2=pd.read_csv('data1.csv')\n",
    "        columns= data_info2.iloc[0:,0:128]\n",
    "        source_imgs=data_info2.iloc[0:,128:129]\n",
    "        source_imgs=np.array(source_imgs)\n",
    "        rows=columns.shape[0]\n",
    "        marix=np.mat(columns)\n",
    "        distlist=[]\n",
    "        print(marix.shape)\n",
    "        for i in range(rows):\n",
    "            dist = np.sqrt(np.sum(np.square(np.subtract(marix[i,:],emb[0,:]))))\n",
    "            distlist.append(dist)   \n",
    "        b = np.sort(distlist, axis=0)\n",
    "        b1 = np.argsort(distlist)\n",
    "        likesImg=source_imgs[b1]\n",
    "        for i in range(10):\n",
    "            filepath=likesImg[i,0]\n",
    "            lena = mpimg.imread(filepath) \n",
    "            lena.shape #(512, 512, 3)\n",
    "            print(lena.shape)\n",
    "            plt.imshow(lena) # 显示图片\n",
    "            pylab.show()  \n",
    "        \n",
    " \n",
    "\n",
    "style=Faster_style()\n",
    "#style.generate_csv()\n",
    "\n",
    "style.search('image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating networks and loading parameters\n",
      "Model filename: 20170511-185253.pb\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0d84c83f1acd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mcompare\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AnacondaProjects\\facenet-master\\src\\compare.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;31m# Load the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mfacenet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;31m# Get input and output tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AnacondaProjects\\facenet-master\\src\\facenet.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0mgraph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m             \u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_graph_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model directory: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmodel_exp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\u001b[0m in \u001b[0;36mimport_graph_def\u001b[1;34m(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;31m# NOTE(mrry): If the graph contains a cycle, the full shape information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[1;31m# may not be available for this op's inputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m       \u001b[1;31m# For nodes with _output_shapes set, set the output shapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;34m'_output_shapes'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2209\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2210\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2158\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2159\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, require_shape_fn)\u001b[0m\n\u001b[0;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m                                   require_shape_fn)\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    684\u001b[0m       output = pywrap_tensorflow.RunCppShapeInference(\n\u001b[0;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    687\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No shape inference function exists for op\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import compare\n",
    "import sys\n",
    "\n",
    "sys.argv=['compare.py','20170511-185253.pb','image.jpg','image1.jpg']\n",
    "args=compare.parse_arguments(sys.argv[1:])\n",
    "\n",
    "for i in range(100):\n",
    "    compare.main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
