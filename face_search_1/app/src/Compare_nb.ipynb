{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main\n",
      "Creating networks and loading parameters\n",
      "1\n",
      "Model filename: 20170511-185253.pb\n",
      "emb\n",
      "[[ 0.03822617  0.00132316 -0.08310848  0.08076843 -0.04166999 -0.05224595\n",
      "   0.0779245   0.11358331  0.0576144   0.11975975  0.00836389  0.04951916\n",
      "   0.06685825 -0.10810665  0.0888785   0.16669871  0.0684053  -0.02079378\n",
      "  -0.06632908  0.05868777  0.07719178 -0.02777223  0.05059009 -0.08215641\n",
      "  -0.02833533 -0.09729583 -0.02733224  0.10218848 -0.0070738   0.07111225\n",
      "   0.16436757  0.10825212 -0.16880769  0.01497244  0.05991238 -0.04641831\n",
      "  -0.10943218  0.11415453 -0.12867153  0.01492429  0.01397523 -0.01630708\n",
      "  -0.14768681 -0.0186873   0.0245015  -0.03866929  0.16022038  0.09892862\n",
      "  -0.06983804  0.00448961 -0.09779122  0.05427967 -0.14805599 -0.12315276\n",
      "   0.05324348  0.00407345 -0.15981776  0.01774216 -0.00023767 -0.06901793\n",
      "   0.06020534  0.10147775  0.02790588 -0.20616134  0.18834777  0.13748971\n",
      "  -0.07671699 -0.07699957  0.00623676  0.01286855 -0.11944406  0.03283018\n",
      "   0.14803892 -0.11238442 -0.19886257  0.12553601 -0.00783956 -0.06719113\n",
      "  -0.00080887  0.06288575  0.00693893  0.14904861  0.05728525  0.08989389\n",
      "  -0.05593943 -0.00734614  0.07342815 -0.05750759 -0.10926119 -0.04310076\n",
      "  -0.19205989  0.02152608 -0.08600381  0.09908203 -0.03630628 -0.07601485\n",
      "  -0.09508263 -0.10111745  0.0160892  -0.00173808 -0.03206681 -0.03170235\n",
      "  -0.04351336  0.03477296  0.02322554 -0.01867907 -0.23529549 -0.06663963\n",
      "   0.04874982 -0.00885442 -0.06945552  0.00562469  0.07290936  0.07430588\n",
      "  -0.01350203  0.03859662 -0.19941819 -0.04804048 -0.05251842  0.126341\n",
      "  -0.04524684 -0.04424712 -0.06359336 -0.05659112  0.08165999 -0.15345055\n",
      "  -0.06434217 -0.03286683]]\n",
      "Images:\n",
      "0: image1.jpg\n",
      "\n",
      "Distance matrix\n",
      "        0     \n",
      "0  sub\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "square_1\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "sum_1\n",
      "0.0\n",
      "sqrt_sum\n",
      "0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Performs face alignment and calculates L2 distance between the embeddings of images.\"\"\"\n",
    "\n",
    "# MIT License\n",
    "# \n",
    "# Copyright (c) 2016 David Sandberg\n",
    "# \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "# \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "# \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from tensorflow.python.platform import gfile\n",
    "from scipy import misc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import facenet\n",
    "import align.detect_face\n",
    "\n",
    "def __init__(self):\n",
    "        load_model('20170511-185253.pb')\n",
    "     \n",
    "    \n",
    "def load_model(model):\n",
    "    # Check if the model is a model directory (containing a metagraph and a checkpoint file)\n",
    "    #  or if it is a protobuf file with a frozen graph\n",
    "    model_exp = os.path.expanduser(model)\n",
    "    if (os.path.isfile(model_exp)):\n",
    "        print('Model filename: %s' % model_exp)\n",
    "        with gfile.FastGFile(model_exp,'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            tf.import_graph_def(graph_def, name='')\n",
    "    else:\n",
    "        print('Model directory: %s' % model_exp)\n",
    "        meta_file, ckpt_file = get_model_filenames(model_exp)\n",
    "        \n",
    "        print('Metagraph file: %s' % meta_file)\n",
    "        print('Checkpoint file: %s' % ckpt_file)\n",
    "      \n",
    "        saver = tf.train.import_meta_graph(os.path.join(model_exp, meta_file))\n",
    "        saver.restore(tf.get_default_session(), os.path.join(model_exp, ckpt_file))\n",
    "        \n",
    "        \n",
    "def main(args):\n",
    "    print('main')\n",
    "    images = load_and_align_data(args.image_files, args.image_size, args.margin, args.gpu_memory_fraction)\n",
    "    with tf.Graph().as_default():   \n",
    "           # Load the  \n",
    "            sess =tf.Session() \n",
    "            load_model(args.model)\n",
    "    \n",
    "            # Get input and output tensors\n",
    "            images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "            embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "\n",
    "            # Run forward pass to calculate embeddings\n",
    "            feed_dict = { images_placeholder: images, phase_train_placeholder:False }\n",
    "            emb = sess.run(embeddings, feed_dict=feed_dict)\n",
    "            print('emb')\n",
    "            print(emb)\n",
    "            nrof_images = len(args.image_files)\n",
    "\n",
    "            print('Images:')\n",
    "            for i in range(nrof_images):\n",
    "                print('%1d: %s' % (i, args.image_files[i]))\n",
    "            print('')\n",
    "            \n",
    "            # Print distance matrix\n",
    "            print('Distance matrix')\n",
    "            print('    ', end='')\n",
    "            for i in range(nrof_images):\n",
    "                print('    %1d     ' % i, end='')\n",
    "            print('')\n",
    "         \n",
    "            for i in range(nrof_images):\n",
    "                print('%1d  ' % i, end='')\n",
    "                for j in range(nrof_images):\n",
    "                    sub=np.subtract(emb[i,:], emb[j,:])\n",
    "                    print('sub')\n",
    "                    print(sub)\n",
    "                    square_1=np.square(sub);\n",
    "                    print('square_1')\n",
    "                    print(square_1)\n",
    "                    sum_1=np.sum(square_1)\n",
    "                    print('sum_1')\n",
    "                    print(sum_1)\n",
    "                    sqrt_sum=np.sqrt(sum_1)\n",
    "                    print('sqrt_sum')\n",
    "                    print(sqrt_sum)\n",
    "                    dist = np.sqrt(np.sum(np.square(np.subtract(emb[i,:], emb[j,:]))))\n",
    "                   \n",
    "                    #print('  %1.4f  ' % dist, end='')\n",
    "                print('')\n",
    "            \n",
    "            \n",
    "def load_and_align_data(image_paths, image_size, margin, gpu_memory_fraction):\n",
    "\n",
    "    minsize = 20 # minimum size of face  \n",
    "    threshold = [ 0.6, 0.7, 0.7 ]  # three steps's threshold\n",
    "    factor = 0.709 # scale factor\n",
    "    \n",
    "    print('Creating networks and loading parameters')\n",
    "    with tf.Graph().as_default():\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_memory_fraction)\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "        with sess.as_default():\n",
    "            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\n",
    "  \n",
    "    nrof_samples = len(image_paths)\n",
    "    print(nrof_samples)\n",
    "    img_list = [None] * nrof_samples\n",
    "    for i in range(nrof_samples):\n",
    "        img = misc.imread(os.path.expanduser(image_paths[i]), mode='RGB')\n",
    "        img_size = np.asarray(img.shape)[0:2]\n",
    "        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n",
    "        det = np.squeeze(bounding_boxes[0,0:4])\n",
    "        bb = np.zeros(4, dtype=np.int32)\n",
    "        bb[0] = np.maximum(det[0]-margin/2, 0)\n",
    "        bb[1] = np.maximum(det[1]-margin/2, 0)\n",
    "        bb[2] = np.minimum(det[2]+margin/2, img_size[1])\n",
    "        bb[3] = np.minimum(det[3]+margin/2, img_size[0])\n",
    "        cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n",
    "        aligned = misc.imresize(cropped, (image_size, image_size), interp='bilinear')\n",
    "        prewhitened = facenet.prewhiten(aligned)\n",
    "        img_list[i] = prewhitened\n",
    "    images = np.stack(img_list)\n",
    "    return images\n",
    "\n",
    "def parse_arguments(argv):\n",
    "    parser = argparse.ArgumentParser()\n",
    "   \n",
    "    parser.add_argument('model', type=str, \n",
    "        help='Could be either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file')\n",
    "    parser.add_argument('image_files', type=str, nargs='+', help='Images to compare')\n",
    "    parser.add_argument('--image_size', type=int,\n",
    "        help='Image size (height, width) in pixels.', default=160)\n",
    "    parser.add_argument('--margin', type=int,\n",
    "        help='Margin for the crop around the bounding box (height, width) in pixels.', default=44)\n",
    "    parser.add_argument('--gpu_memory_fraction', type=float,\n",
    "        help='Upper bound on the amount of GPU memory that will b e used by wthe process.', default=1.0)\n",
    "    return parser.parse_args(argv)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sys.argv=['compare.py','20170511-185253.pb','image1.jpg']\n",
    "    main(parse_arguments(sys.argv[1:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
